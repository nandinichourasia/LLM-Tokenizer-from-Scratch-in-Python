# LLM-Tokenizer-from-Scratch-in-Python
Building a tokenizer from scratch is a foundational step in developing a Large Language Model (LLM).
# What Is a Tokenizer?
-A tokenizer converts raw text into smaller units called tokens, which are then mapped to numerical IDs. This process enables models to process and understand text data effectively.
# How do we prepare input text for training LLMs?
Step1- Splitting the text into individual word and subword.
Step2- Convert Tokens(Individual word) into Token IDs.
Step3- Encode token IDs into Vector Representations.
